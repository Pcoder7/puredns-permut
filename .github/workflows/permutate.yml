name: Distributed PureDNS - Dispatcher

on:
  workflow_dispatch:

permissions:
  contents: write   # For creating matrix.json, artifacts, and potentially committing aggregated results
  actions: write    # For triggering workflows in Account 2's repository

env:
  LINES_PER_CHUNK: 80
  PRIMARY_ACCOUNT_MAX_PARALLEL: 20 # Max parallel jobs for THIS account's resolve job
  # Define Account 2 repo details here or get from secrets for more flexibility
  ACCOUNT2_REPO_OWNER: ${{ secrets.ACCOUNT2_REPO_OWNER || 'pushrockzz' }} # Fallback for testing
  ACCOUNT2_REPO_NAME: ${{ secrets.ACCOUNT2_REPO_NAME || 'puredns-resolve' }} # Fallback for testing

jobs:
  prepare_all_chunks_and_package:
    name: Prepare All Chunks & Package
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GHCR_TOKEN }}
    outputs:
      # Output 1: The full JSON matrix string of ALL generated chunks
      all_chunks_matrix_json: ${{ steps.build_full_matrix.outputs.full_matrix }}
      # Output 2: The total number of chunks generated
      total_chunks_count: ${{ steps.build_full_matrix.outputs.total_chunks }}
      # Output 3: The name of the artifact containing all chunks and resolvers
      chunk_package_artifact_name: "all-chunks-package-${{ github.run_id }}"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: DEBUG - Verify Tools and Initial File System State
        shell: bash
        run: |
          echo "DEBUG: Current directory: $(pwd)"
          echo "DEBUG: Listing all files in repository root and subdirectories:"
          find . -print
          echo "-----------------------------------------------------"
          echo "DEBUG: Specifically looking for subdomains.txt files:"
          find . -type f -name 'subdomains.txt' -print || echo "DEBUG: 'find' for subdomains.txt failed or found nothing."
          echo "-----------------------------------------------------"
          echo "DEBUG: Checking for 'jq' command..."
          if ! command -v jq &> /dev/null; then
            echo "CRITICAL_ERROR: 'jq' command not found. This is essential. Aborting."
            exit 1
          else
            echo "DEBUG: jq version: $(jq --version)"
          fi
          echo "-----------------------------------------------------"
          echo "DEBUG: Checking for 'split' command..."
          if ! command -v split &> /dev/null; then
            echo "CRITICAL_ERROR: 'split' command not found. This is essential. Aborting."
            exit 1
          else
            echo "DEBUG: split version information (if available):"
            split --version || echo "DEBUG: Could not get split version."
          fi
          echo "-----------------------------------------------------"

      - name: Build Full Matrix & Create Chunks
        id: build_full_matrix
        shell: bash
        run: |
          # --- Start of Script ---
          JSON_MATRIX='[]' # Initialize as an empty JSON array string
          echo "INFO: Initializing JSON_MATRIX as: '$JSON_MATRIX'"

          echo "INFO: Locating 'subdomains.txt' files..."
          find . -type f -name "subdomains.txt" -print0 > found_files.tmp

          declare -a files=() # Explicitly declare as an array
          while IFS= read -r -d $'\0' file_path_from_find; do
            standardized_file_path=$(echo "$file_path_from_find" | sed 's|^\./||')
            files+=("$standardized_file_path")
          done < found_files.tmp
          rm found_files.tmp # Clean up temporary file

          if [ "${#files[@]}" -eq 0 ]; then
            echo "WARNING: No 'subdomains.txt' files found in the repository."
            echo "INFO: JSON_MATRIX will remain '[]'. No chunks will be generated."
          else
            echo "INFO: Found ${#files[@]} 'subdomains.txt' file(s):"
            printf "  => '%s'\n" "${files[@]}" # Print each found file for clarity

            for file_path in "${files[@]}"; do
              echo "-----------------------------------------------------"
              echo "INFO: Processing file: '$file_path'"

              domain_dir=$(dirname "$file_path")
              if [ "$domain_dir" == "." ]; then
                domain=$(basename "$file_path" .txt)
              else
                domain=$(basename "$domain_dir")
              fi
              echo "INFO: Deduced domain: '$domain'"

              if [ ! -f "$file_path" ]; then
                echo "ERROR: File '$file_path' reported by find, but not found now. Skipping."
                continue
              fi
              if [ ! -s "$file_path" ]; then
                echo "WARNING: File '$file_path' is empty. Skipping splitting for this file."
                continue
              fi

              echo "INFO: Creating chunk directory 'chunks/$domain' if it doesn't exist."
              mkdir -p "chunks/$domain"

              output_chunk_prefix="chunks/$domain/chunk_"
              echo "INFO: Splitting '$file_path' into chunks in 'chunks/$domain/' with prefix '$output_chunk_prefix' (max $LINES_PER_CHUNK lines/chunk)"
              
              split -l "$LINES_PER_CHUNK" -a 3 --numeric-suffixes=1 "$file_path" "$output_chunk_prefix"
              split_exit_code=$?
              if [ $split_exit_code -ne 0 ]; then
                echo "ERROR: 'split' command failed with exit code $split_exit_code for file '$file_path'. Skipping chunk generation for this file."
                continue
              fi
              
              CHUNK_COUNT_FOR_THIS_FILE=0
              while IFS= read -r chunk_file_path; do
                if [ -z "$chunk_file_path" ]; then continue; fi

                echo "DEBUG: Processing chunk_file_path: '$chunk_file_path' for domain '$domain'"
                echo "DEBUG: Current JSON_MATRIX before jq (first 100 chars): $(echo "$JSON_MATRIX" | head -c 100)"
                echo "DEBUG: Validating current JSON_MATRIX with jq -e:"
                if echo "$JSON_MATRIX" | jq -e . > /dev/null 2>&1; then
                  echo "DEBUG: Current JSON_MATRIX is VALID."
                else
                  echo "CRITICAL_ERROR_DETECTED: Current JSON_MATRIX is INVALID before processing '$chunk_file_path'."
                  echo "CRITICAL_ERROR_DETECTED: JSON_MATRIX content: $JSON_MATRIX"
                  if [ "$JSON_MATRIX" != "[]" ] && [ "$CHUNK_COUNT_FOR_THIS_FILE" -gt 0 ]; then
                      echo "ABORTING chunk addition for this file due to previously corrupted JSON_MATRIX."
                      break 
                  else
                      echo "WARNING: JSON_MATRIX was invalid but appeared to be at an initial state. Attempting to reset to []."
                      JSON_MATRIX="[]"
                  fi
                fi
                
                if ! command -v jq &> /dev/null; then
                  echo "CRITICAL_ERROR: 'jq' command not found during chunk processing. Aborting this file's chunk addition."
                  break 
                fi
                
                echo "DEBUG: jq command to be run: printf '%s' \"\$JSON_MATRIX\" | jq -c --arg d \"$domain\" --arg c \"$chunk_file_path\" '. + [{domain:\$d,chunk:\$c}]'"
                TEMP_JSON_MATRIX=$(printf '%s' "$JSON_MATRIX" | jq -c --arg d "$domain" --arg c "$chunk_file_path" '. + [{domain:$d,chunk:$c}]')
                jq_exit_code=$?

                if [ $jq_exit_code -ne 0 ]; then
                  echo "ERROR: jq command failed (exit code $jq_exit_code) when trying to add chunk '$chunk_file_path' for domain '$domain'."
                  echo "ERROR: Input JSON_MATRIX was (first 100 chars): $(echo "$JSON_MATRIX" | head -c 100)"
                  echo "ERROR: Arguments to jq were: domain='$domain', chunk_file_path='$chunk_file_path'"
                  continue
                elif [ -z "$TEMP_JSON_MATRIX" ]; then
                  echo "ERROR: jq command produced empty output for chunk '$chunk_file_path'. This should not happen with '. + [...]'."
                  echo "ERROR: Input JSON_MATRIX that led to empty output (first 200 chars): $(echo "$JSON_MATRIX" | head -c 200)"
                  echo "ERROR: Full input JSON_MATRIX that led to empty output: $JSON_MATRIX"
                  echo "ERROR: Arguments to jq were: domain='$domain', chunk_file_path='$chunk_file_path'"
                  echo "DEBUG: Re-validating the input JSON_MATRIX that caused empty output:"
                  if echo "$JSON_MATRIX" | jq -e . > /dev/null 2>&1; then
                      echo "DEBUG: Input JSON_MATRIX was still considered VALID by jq -e just before the empty output. This is very strange."
                  else
                      echo "DEBUG: Input JSON_MATRIX was considered INVALID by jq -e. This is the likely cause of empty output."
                  fi
                  if [ "$JSON_MATRIX" == "" ]; then
                      echo "DEBUG: JSON_MATRIX was an empty string. Trying to initialize with the current chunk."
                      TEMP_JSON_MATRIX=$(jq -cn --arg d "$domain" --arg c "$chunk_file_path" '[{domain:$d,chunk:$c}]')
                      if [ -n "$TEMP_JSON_MATRIX" ]; then
                          echo "DEBUG: Successfully initialized TEMP_JSON_MATRIX from empty string case."
                      else
                          echo "ERROR: Still failed to initialize TEMP_JSON_MATRIX even from empty string case."
                          continue
                      fi
                  else
                      continue 
                  fi
                fi

                JSON_MATRIX="$TEMP_JSON_MATRIX"
                CHUNK_COUNT_FOR_THIS_FILE=$((CHUNK_COUNT_FOR_THIS_FILE + 1))
                echo "DEBUG: Successfully added/updated for chunk '$chunk_file_path'. JSON_MATRIX (first 100 chars): $(echo "$JSON_MATRIX" | head -c 100)"
              done < <(find "chunks/$domain/" -name 'chunk_*' -type f -print)

              if [ "$CHUNK_COUNT_FOR_THIS_FILE" -eq 0 ]; then
                echo "WARNING: No chunk files were processed/added to matrix for '$file_path' in domain '$domain'. 'split' might have created no files, or 'jq' failed for all."
              else
                echo "INFO: Processed and added $CHUNK_COUNT_FOR_THIS_FILE chunk(s) to matrix for domain '$domain' from '$file_path'."
              fi
            done
          fi

          echo "-----------------------------------------------------"
          if ! echo "$JSON_MATRIX" | jq -e . > /dev/null 2>&1; then
            echo "ERROR: Final JSON_MATRIX is not valid JSON. Content (first 200 chars): $(echo "$JSON_MATRIX" | head -c 200)"
            echo "WARNING: Setting JSON_MATRIX to '[]' and total_chunks to 0 due to invalid JSON."
            JSON_MATRIX="[]"
            TOTAL_CHUNKS=0
          else
            TOTAL_CHUNKS=$(echo "$JSON_MATRIX" | jq 'length')
          fi

          echo "FINAL_BUILD_INFO: Final JSON_MATRIX content (first 200 chars): $(echo "$JSON_MATRIX" | head -c 200)"
          echo "FINAL_BUILD_INFO: Total chunks in matrix: $TOTAL_CHUNKS"

          echo "INFO: Writing the final matrix to 'full_matrix.json' file..."
          echo "$JSON_MATRIX" > full_matrix.json

          if [ -f full_matrix.json ]; then
            echo "VERIFY: 'full_matrix.json' created. Size: $(wc -c < full_matrix.json) bytes."
            echo "VERIFY: Content preview of 'full_matrix.json' (first 200 chars): $(head -c 200 full_matrix.json)"
            if jq -e . full_matrix.json > /dev/null 2>&1; then
              echo "VERIFY: 'full_matrix.json' contains valid JSON."
            else
              echo "ERROR: 'full_matrix.json' does NOT contain valid JSON! This will cause issues for 'fromJson' later."
            fi
          else
            echo "CRITICAL_ERROR: 'full_matrix.json' was NOT created after attempting to write JSON_MATRIX."
            echo "INFO: Forcing 'full_matrix.json' to be '[]' as a fallback to prevent tar error."
            echo "[]" > full_matrix.json
          fi

          echo "full_matrix=$JSON_MATRIX" >> $GITHUB_OUTPUT
          echo "total_chunks=$TOTAL_CHUNKS" >> $GITHUB_OUTPUT                 

      - name: Package All Chunks and Resolvers      
        id: package_chunks # This ID is referenced by outputs and later steps
        if: steps.build_full_matrix.outputs.total_chunks > 0
        shell: bash
        run: |
          # Define the base name for the artifact (without .tar.gz)
          BASE_ARTIFACT_NAME="all-chunks-package-${{ github.run_id }}"
          # Define the full tar filename
          PACKAGE_TAR_FILENAME="${BASE_ARTIFACT_NAME}.tar.gz"

          echo "INFO: Preparing package '$PACKAGE_TAR_FILENAME'..."
          # Ensure resolver files and full_matrix.json exist, create fallbacks if not
          if [ ! -f resolvers.txt ]; then echo "WARNING: resolvers.txt not found, creating default." >&2; echo '1.1.1.1' > resolvers.txt; fi
          if [ ! -f resolvers-trusted.txt ]; then echo "WARNING: resolvers-trusted.txt not found, creating empty." >&2; touch resolvers-trusted.txt; fi
          if [ ! -f full_matrix.json ]; then echo "WARNING: full_matrix.json not found, creating empty array JSON file." >&2; echo "[]" > full_matrix.json; fi
          
          # Create the tarball
          echo "INFO: Creating tarball: $PACKAGE_TAR_FILENAME"
          tar -czvf "$PACKAGE_TAR_FILENAME" chunks resolvers.txt resolvers-trusted.txt full_matrix.json
          
          if [ $? -eq 0 ]; then
            echo "INFO: '$PACKAGE_TAR_FILENAME' created successfully."
          else
            echo "ERROR: Failed to create tarball '$PACKAGE_TAR_FILENAME'."
            # Exit or handle error appropriately if tar fails
            exit 1 
          fi
          
          # Output the full .tar.gz filename for the 'path' in upload-artifact
          echo "package_tar_filename=$PACKAGE_TAR_FILENAME" >> $GITHUB_OUTPUT
          # Output the base artifact name (without .tar.gz) for the 'name' in upload-artifact and for job output
          echo "base_artifact_name=$BASE_ARTIFACT_NAME" >> $GITHUB_OUTPUT

      - name: Upload Full Chunks Package
        if: steps.build_full_matrix.outputs.total_chunks > 0 && steps.package_chunks.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          # Use the base artifact name output from the 'package_chunks' step
          name: ${{ steps.package_chunks.outputs.base_artifact_name }}
          # Use the full tar filename output from the 'package_chunks' step
          path: ${{ steps.package_chunks.outputs.package_tar_filename }}
          retention-days: 2

  distribute_and_trigger_secondary:
    name: Distribute Work & Trigger Secondary
    needs: prepare_all_chunks_and_package
    if: needs.prepare_all_chunks_and_package.outputs.total_chunks_count > 0 # Only run if there are chunks
    runs-on: ubuntu-latest
    outputs:
      primary_matrix_json: ${{ steps.calculate_distribution.outputs.primary_matrix }}
      secondary_processing_triggered: ${{ steps.trigger_secondary.outcome == 'success' && steps.calculate_distribution.outputs.secondary_chunks_exist == 'true' }}
    steps:
      - name: Calculate Chunk Distribution for Accounts
        id: calculate_distribution
        shell: bash
        run: |
          ALL_CHUNKS_JSON='${{ needs.prepare_all_chunks_and_package.outputs.all_chunks_matrix_json }}'
          PRIMARY_MAX_PARALLEL=${{ env.PRIMARY_ACCOUNT_MAX_PARALLEL }}
          
          echo "Full matrix (first 200 chars): $(echo "$ALL_CHUNKS_JSON" | head -c 200)"
          echo "Primary account max parallel: $PRIMARY_MAX_PARALLEL"

          # Chunks for Account 1 (Primary)
          CHUNKS_FOR_PRIMARY=$(echo "$ALL_CHUNKS_JSON" | jq -c --argjson limit "$PRIMARY_MAX_PARALLEL" '.[0:$limit]')
          echo "primary_matrix=$CHUNKS_FOR_PRIMARY" >> $GITHUB_OUTPUT
          echo "Primary matrix (first 200 chars): $(echo "$CHUNKS_FOR_PRIMARY" | head -c 200)"

          # Chunks for Account 2 (Secondary)
          CHUNKS_FOR_SECONDARY=$(echo "$ALL_CHUNKS_JSON" | jq -c --argjson offset "$PRIMARY_MAX_PARALLEL" '.[$offset:]')
          SECONDARY_COUNT=$(echo "$CHUNKS_FOR_SECONDARY" | jq 'length')

          if [ "$SECONDARY_COUNT" -eq 0 ]; then
            echo "No chunks remaining for secondary account."
            echo "secondary_matrix=[]" >> $GITHUB_OUTPUT
            echo "secondary_chunks_exist=false" >> $GITHUB_OUTPUT
          else
            echo "Secondary matrix (first 200 chars): $(echo "$CHUNKS_FOR_SECONDARY" | head -c 200)"
            echo "secondary_matrix=$CHUNKS_FOR_SECONDARY" >> $GITHUB_OUTPUT
            echo "secondary_chunks_exist=true" >> $GITHUB_OUTPUT
          fi
      
      - name: Prepare Trigger Payload
        id: prepare_payload
        if: steps.calculate_distribution.outputs.secondary_chunks_exist == 'true'
        shell: bash
        run: |
          # Ensure the secondary_matrix output from the previous step is treated as a string
          # that already represents a JSON array. jq's --argjson will parse it.
          SECONDARY_MATRIX_AS_STRING='${{ steps.calculate_distribution.outputs.secondary_matrix }}'

          # Validate that SECONDARY_MATRIX_AS_STRING is actually valid JSON before --argjson
          if ! echo "${SECONDARY_MATRIX_AS_STRING}" | jq -e . > /dev/null 2>&1; then
            echo "::error title=Invalid Secondary Matrix::The secondary_matrix output ('${SECONDARY_MATRIX_AS_STRING}') is not valid JSON. Defaulting to empty array."
            SECONDARY_MATRIX_AS_STRING="[]" # Fallback to an empty JSON array string
          fi

          # Construct the entire payload as a valid JSON string using jq
          # --argjson tells jq to parse the value of matrix_json as JSON, not treat it as a literal string
          JSON_PAYLOAD=$(jq -cn \
            --arg run_id "${{ github.run_id }}" \
            '{
              "primary_run_id": $run_id
            }')
             echo "Constructed JSON Payload: $JSON_PAYLOAD"
             echo "json_string=$JSON_PAYLOAD" >> "$GITHUB_OUTPUT"
           
          JSON_PAYLOAD=$(jq -cn \
            --arg server_url "${{ github.server_url }}" \
            --arg repo_owner "${{ github.repository_owner }}" \
            --arg repo_name "${{ github.event.repository.name }}" \
            --arg run_id "${{ github.run_id }}" \
            --arg artifact_name "${{ needs.prepare_all_chunks_and_package.outputs.chunk_package_artifact_name }}" \
            --arg matrix_as_a_string "${SECONDARY_MATRIX_AS_STRING}" \
            '{
              "primary_github_server_url": $server_url,
              "primary_repo_owner": $repo_owner,
              "primary_repo_name": $repo_name,
              "primary_run_id": $run_id,
              "chunk_package_artifact_name": $artifact_name,
              "secondary_matrix_json": $matrix_as_a_string 
            }')
          
          echo "Constructed JSON Payload: $JSON_PAYLOAD"
          # Set the constructed JSON string as an output of this step
          echo "json_string=$JSON_PAYLOAD" >> $GITHUB_OUTPUT
      
      - name: DEBUG - Show Exact Inputs String
        id: debug_show_inputs
        run: |
          INPUTS_STRING="${{ steps.prepare_payload.outputs.json_string }}"
          echo "DEBUG: Exact string value being passed to 'inputs':"
          echo "$INPUTS_STRING"
          echo "DEBUG: Length of inputs string: ${#INPUTS_STRING}"

      - name: Trigger Secondary Account Workflow
        id: trigger_secondary 
        if: steps.calculate_distribution.outputs.secondary_chunks_exist == 'true'
        uses: benc-uk/workflow-dispatch@v1
        with:
          workflow: resolve.yml 
          repo: ${{ env.ACCOUNT2_REPO_OWNER }}/${{ env.ACCOUNT2_REPO_NAME }}
          token: ${{ secrets.PAT_FOR_SECONDARY_ACCOUNT_REPO }}
          inputs: ${{ steps.prepare_payload.outputs.json_string }}
          ref: main # Or your default branch name in Account 2

  resolve_primary_account_chunks:
    name: Resolve Primary Account Chunks (puredns + dsieve)
    needs: [prepare_all_chunks_and_package, distribute_and_trigger_secondary] # Depends on distribution logic
    if: needs.prepare_all_chunks_and_package.outputs.total_chunks_count > 0 && needs.distribute_and_trigger_secondary.outputs.primary_matrix_json != '[]'
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GHCR_TOKEN }}    
    strategy:
      fail-fast: false
      max-parallel: 20 
      matrix:
        pair: ${{ fromJson(needs.distribute_and_trigger_secondary.outputs.primary_matrix_json) }}
    steps:
      - name: Checkout repository (for results structure)
        uses: actions/checkout@v3

      - name: Download Full Chunks Package for Primary
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.prepare_all_chunks_and_package.outputs.chunk_package_artifact_name }}
          # Downloads to current directory

      - name: Extract Chunks for Primary
        shell: bash
        run: |
          PACKAGE_FILENAME="${{ needs.prepare_all_chunks_and_package.outputs.chunk_package_artifact_name }}.tar.gz"
          echo "Extracting $PACKAGE_FILENAME..."
          tar -xzvf "$PACKAGE_FILENAME"
          if [ ! -d "chunks" ]; then
             echo "ERROR: 'chunks/' not found after extraction!"
             exit 1
          fi
          echo "Extraction complete. 'chunks/' should be present."
          ls -R chunks/

      - name: Set up Go & install dsieve
        uses: actions/setup-go@v4
        with:
          go-version: '1.23'
      - name: Install dsieve
        run: |
          if command -v dsieve &> /dev/null; then
            echo "dsieve is already installed"
          else
            echo "Installing dsieve..."
            go install github.com/trickest/dsieve@latest
          fi

      - name: Run puredns + pre-dsieve on subdomains + final filtering
        shell: bash
        run: |
          DOMAIN=${{ matrix.pair.domain }}
          CHUNK_FILE_PATH=${{ matrix.pair.chunk }}   # e.g. "chunks/example.com/chunk_001"
          echo "Processing domain '$DOMAIN' with chunk '$CHUNK_FILE_PATH'..."

          if [ ! -f "$CHUNK_FILE_PATH" ]; then
            echo "ERROR: Chunk file '$CHUNK_FILE_PATH' not found!"
            exit 1
          fi

          # ───────────────────────────────────────────────────────────
          # Step A: pre-dsieve on the raw subdomain chunk (no puredns yet)
          # ───────────────────────────────────────────────────────────
          echo "-> Generating parent_domains.txt from raw subdomains..."
          dsieve -if "$CHUNK_FILE_PATH" -f 2 | sort -u > parent_domains.txt

          echo "  Parents in this chunk: $(wc -l < parent_domains.txt)"
          head -n 5 parent_domains.txt || true

          # ───────────────────────────────────────────────────────────
          # Step B: Probe all subdomains in this chunk with puredns
          # ───────────────────────────────────────────────────────────
          PUREDNS_OUT="puredns_output.txt"
          echo "-> Running puredns against '$CHUNK_FILE_PATH'..."
          puredns resolve "$CHUNK_FILE_PATH" \
            -r resolvers.txt \
            --resolvers-trusted resolvers-trusted.txt \
            --write "$PUREDNS_OUT" \
            --write-wildcards "$WILDCARD_FILE" \
            --wildcard-batch 100000 --wildcard-tests 250
            

          puredns_exit=$?
          if [ $puredns_exit -ne 0 ]; then
            echo "ERROR: puredns returned exit code $puredns_exit. Aborting chunk."
            exit 1
          fi

          # Always create results/ so upload-artifact sees at least an empty folder
          OUTPUT_ROOT="results"
          mkdir -p "$OUTPUT_ROOT"

          if [ ! -s "$PUREDNS_OUT" ]; then
            echo "No live hostnames found in this chunk. Leaving results/ empty."
            exit 0
          fi

          echo "-> Sample of puredns_output.txt (first 5 lines):"
          head -n 5 "$PUREDNS_OUT" || true

          # ───────────────────────────────────────────────────────────
          # Step C+D: For each parent domain, filter matching hostnames
          # ───────────────────────────────────────────────────────────
          echo "DEBUG: Starting per-parent filtering with AWK (domain-only mode)"
          while read -r parent; do
            # Strip any carriage returns or trailing whitespace
            clean_parent=$(printf '%s' "$parent" | tr -d '\r' | xargs)
            if [ -z "$clean_parent" ]; then
              echo "DEBUG: Skipping empty parent line"
              continue
            fi

            echo "DEBUG: Processing parent => [[$clean_parent]]"
            mkdir -p "$OUTPUT_ROOT/$clean_parent"
            outfile="$OUTPUT_ROOT/$clean_parent/puredns_result.txt"

            echo "DEBUG: AWK filtering host==$clean_parent or subdomain of $clean_parent from $PUREDNS_OUT into $outfile"

            awk -v b="$clean_parent" '
            {
              host = $1
              if (host == b || host ~ ("\\." b "$")) {
                print $0
              }
            }
            ' "$PUREDNS_OUT" > "$outfile" 2>/tmp/awk_error.log
            awk_exit=$?
            if [ $awk_exit -ne 0 ]; then
              echo "ERROR: AWK exited with code $awk_exit for parent='$clean_parent'."
              echo "DEBUG: Contents of /tmp/awk_error.log:"
              cat /tmp/awk_error.log || true
            fi

            if [ -f "$outfile" ]; then
              lines_written=$(wc -l < "$outfile")
              echo "DEBUG: '$outfile' contains $lines_written line(s)."
              if [ $lines_written -gt 0 ]; then
                echo "DEBUG: Sample lines from '$outfile':"
                head -n 3 "$outfile" || true
              else
                echo "DEBUG: '$outfile' is empty."
              fi
            else
              echo "DEBUG: '$outfile' was not created."
            fi

          done < parent_domains.txt

          echo "-> Split complete for domain '$DOMAIN'."
          # Always create a results/ directory (so upload-artifact never complains about “no files”)
          mkdir -p results
      
      - name: Compute SAFE_CHUNK (no slashes)
        run: |
          SAFE_CHUNK="${{ matrix.pair.chunk }}"
          SAFE_CHUNK="$(echo "$SAFE_CHUNK" | tr '/' '_')"
          echo "SAFE_CHUNK=$SAFE_CHUNK" >> $GITHUB_ENV         
      
      - name: Upload Primary Account puredns+dsieve Results
        uses: actions/upload-artifact@v4
        with:
          name: primary_purednss_dsieve_${{ matrix.pair.domain }}_${{ env.SAFE_CHUNK }}
          path: results/
          retention-days: 1
